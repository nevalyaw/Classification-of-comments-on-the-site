{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начинаем с добавления всех необходимых библиотек и функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавление библиотек и функций:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и посмотрим общую информацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных:\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу видим, что пропусков в данных нет. Проверим на дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка на дубликаты:\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, интересно, какая часть комментариев помечена как токсичная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токсичных комментариев от общего числа: 0.10161213369158527\n"
     ]
    }
   ],
   "source": [
    "# Небольшое исследование - сколько токсичных комментариев:\n",
    "print('Токсичных комментариев от общего числа:', df['toxic'][df['toxic']==1].count()/df['toxic'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Промежуточный вывод:\n",
    "Были загружены и осмотрены предоставленные данные. Пропусков и нулевых значений не обнаружено. Из интересного - доля токсичных комментариев от общего числа составила 10%; это может усложнить разбиение на выборки и дальнейшее обучение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим ко второй части предобработки. Сперва удалим лишний столбец Unnamed, который дублирует индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Удаление лишнего столбца:\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь \"очистим\" данные от лишних символов и лемматизируем их. Для этого используем изученные функции работы с текстами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89012</th>\n",
       "      <td>support split I d try condense it but it s rat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  toxic\n",
       "89012  support split I d try condense it but it s rat...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Обработка с помощью spacy:\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def clean_text(text):\n",
    "    clean = nlp(\" \".join(re.sub(r'[^a-zA-z]', ' ', text).split()))\n",
    "    lemm_out = ' '.join([w.lemma_ for w in clean])\n",
    "    return lemm_out\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "display(df.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  The striped bats are hanging on their feet for...\n",
      "1      you should be ashamed of yourself went worked\n",
      "0    the stripe bat be hang on their foot for good\n",
      "1        you should be ashamed of yourself go work\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "print(df_my)\n",
    "\n",
    "\n",
    "print(df_my['text'].apply(clean_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось разделить данные на выборки и проследить, чтобы соотношение токсичных и обычных комментариев в тренировочной выборке было одинаковым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на выборки:\n",
    "features = df.drop(['toxic'], axis=1) \n",
    "target = df.toxic\n",
    "RANDOME_STATE = 12345\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=.2, \n",
    "                                                                              random_state=RANDOME_STATE)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=.5,\n",
    "                                                                            random_state=RANDOME_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля значений 1 в тренировочной выборке: 0.10166911239631807\n"
     ]
    }
   ],
   "source": [
    "# Смотрим соотношение в тренировочной выборке:\n",
    "count_0 = len(target_train[target_train==0])\n",
    "count_1 = len(target_train[target_train==1])\n",
    "\n",
    "print('Доля значений 1 в тренировочной выборке:', count_1 / (count_1 + count_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отношение такое же, как и в оригинальной выборке. Для адекватного обучения моделей необходимо сравнять его, механически перемешаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Соотношение в тренировочной выборке:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Уменьшение \"нулевых\" строк:\n",
    "\n",
    "df_train = df.iloc[target_train.index]\n",
    "target_train_0 = df_train[df_train['toxic'] == 0]['toxic']\n",
    "target_train_1 = df_train[df_train['toxic'] == 1]['toxic']\n",
    "\n",
    "\n",
    "target_train_0_resample = target_train_0.sample(target_train_1.shape[0], random_state=RANDOME_STATE)\n",
    "target_train_resample = pd.concat([target_train_0_resample, target_train_1])\n",
    "\n",
    "features_train_resample = df.iloc[target_train_resample.index]\n",
    "\n",
    "features_train_resample, target_train_resample = shuffle(features_train_resample,\n",
    "                                                         target_train_resample,\n",
    "                                                         random_state=RANDOME_STATE)\n",
    "\n",
    "features_train_resample = features_train_resample.text \n",
    "\n",
    "display('Соотношение в тренировочной выборке:', target_train_resample.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "Были загружены и осмотрены предоставленные данные. Пропусков и нулевых значений не обнаружено. Из интересного - доля токсичных комментариев от общего числа составила 10%.\n",
    "\n",
    "Далее: \n",
    "  - Удалён ненужный стобец, дублирующий индексы;\n",
    "  - Произведено преобразование текстовых данных (убраны лишние слова, сделана лемматизация);\n",
    "  - Произведено разбиение на тренировочную, валидационную и тестовую выборки, выровнено количество \"нулевых\" таргетов в тренировочной выборке.\n",
    "  \n",
    "Данные полностью готовы для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения и выбора лучшейц обучим 4 модели: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, CatBoostClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ради удобства и компактности напишем по одной ячейке для каждой модели. Сделаем предсказания на валидационных выборках, выберем лучшую модель по ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Правка типа:\n",
    "features_train = features_train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии: 0.77\n",
      "при параметрах {'lr__C': 10, 'lr__max_iter': 200, 'lr__random_state': 12345, 'lr__solver': 'lbfgs'}\n",
      "\n",
      "F1 логистической регрессии на валидации: 0.78\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression:\n",
    "\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga', 'lbfgs'),\n",
    "              'lr__C': (1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200])}\n",
    "\n",
    "# Обучение модели:\n",
    "\n",
    "grid_search_lr = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_lr.fit(features_train, target_train)\n",
    "\n",
    "mean_test_score = grid_search_lr.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mean_test_score)\n",
    "\n",
    "print('F1 логистической регрессии:', round(lr_train_f1,2))\n",
    "print('при параметрах', grid_search_lr.best_params_)\n",
    "print()\n",
    "\n",
    "# Валидационная выборка:\n",
    "predictions_valid = grid_search_lr.predict(features_valid.text)\n",
    "lr_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 логистической регрессии на валидации:', round(lr_valid_f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 дерева решений: 0.72\n",
      "при параметрах {'dtc__max_depth': 24, 'dtc__random_state': 12345}\n",
      "\n",
      "F1 дерева решений на валидации: 0.63\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier:\n",
    "\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"dtc\", DecisionTreeClassifier())])\n",
    "    \n",
    "parameters = {'dtc__max_depth': ([x for x in range(1, 25)]),\n",
    "              'dtc__random_state': ([12345])}\n",
    "\n",
    "# Обучение модели:\n",
    "\n",
    "grid_search_dt = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_dt.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mean_test_score = grid_search_dt.cv_results_['mean_test_score']\n",
    "dtc_train_f1 = max(mean_test_score)\n",
    "\n",
    "print('F1 дерева решений:', round(dtc_train_f1,2))\n",
    "print('при параметрах', grid_search_dt.best_params_)\n",
    "print()\n",
    "\n",
    "# Валидационная выборка:\n",
    "predictions_valid = grid_search_dt.predict(features_valid.text)\n",
    "dtc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 дерева решений на валидации:', round(dtc_valid_f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoostClassifier: 0.88\n",
      "при параметрах {'cbc__class_weights': (1, 1), 'cbc__iterations': 200, 'cbc__verbose': False}\n",
      "\n",
      "F1 CatBoostClassifier на валидации: 0.73\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier:\n",
    "\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"cbc\", CatBoostClassifier())])\n",
    "    \n",
    "parameters = {'cbc__verbose': ([False]),\n",
    "              'cbc__iterations': ([200]),\n",
    "              'cbc__class_weights':([(1, 1), (1, 5)])}\n",
    "\n",
    "# Обучение модели:\n",
    "\n",
    "grid_search_cb = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_cb.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mean_test_score = grid_search_cb.cv_results_['mean_test_score']\n",
    "cbc_train_f1 = max(mean_test_score)\n",
    "\n",
    "print('F1 CatBoostClassifier:', round(cbc_train_f1,2))\n",
    "print('при параметрах', grid_search_cb.best_params_)\n",
    "print()\n",
    "\n",
    "# Валидационная выборка:\n",
    "predictions_valid = grid_search_cb.predict(features_valid.text)\n",
    "cbc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 CatBoostClassifier на валидации:', round(cbc_valid_f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 случайного леса: 0.79\n",
      "при параметрах {'rfc__class_weight': 'balanced', 'rfc__criterion': 'entropy', 'rfc__max_depth': 9, 'rfc__n_estimators': 29, 'rfc__random_state': 12345}\n",
      "\n",
      "F1 случайного леса на валидации: 0.32\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier:\n",
    "\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"rfc\", RandomForestClassifier())])\n",
    "    \n",
    "parameters = {'rfc__n_estimators': ([x for x in range(10, 30)]),\n",
    "              'rfc__random_state': ([12345]),\n",
    "              'rfc__max_depth': ([x for x in range(1, 10)]),\n",
    "              'rfc__criterion': (['entropy']),\n",
    "              'rfc__class_weight': (['balanced'])}\n",
    "\n",
    "# Обучение модели:\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_rf.fit(features_train_resample, target_train_resample)\n",
    "\n",
    "mean_test_score = grid_search_rf.cv_results_['mean_test_score']\n",
    "rfc_train_f1 = max(mean_test_score)\n",
    "\n",
    "print('F1 случайного леса:', round(rfc_train_f1,2))\n",
    "print('при параметрах', grid_search_rf.best_params_)\n",
    "print()\n",
    "\n",
    "# Валидационная выборка:\n",
    "predictions_valid = grid_search_rf.predict(features_valid.text)\n",
    "rfc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 случайного леса на валидации:', round(rfc_valid_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для лучшего понимания ситуации сведём полученные результаты в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "      <th>F1 на валидационной выборке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.771768</td>\n",
       "      <td>0.782548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.876559</td>\n",
       "      <td>0.730687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.720390</td>\n",
       "      <td>0.629715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.788554</td>\n",
       "      <td>0.323490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке  F1 на валидационной выборке\n",
       "LogisticRegression                     0.771768                     0.782548\n",
       "CatBoostClassifier                     0.876559                     0.730687\n",
       "DecisionTreeClassifier                 0.720390                     0.629715\n",
       "RandomForestClassifier                 0.788554                     0.323490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создание сводки:\n",
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier',\n",
    "         'RandomForestClassifier']\n",
    "\n",
    "data = {'F1 на кросс-валидационной выборке': [lr_train_f1,\n",
    "                                    dtc_train_f1,\n",
    "                                    cbc_train_f1,\n",
    "                                    rfc_train_f1],\n",
    "        \n",
    "        'F1 на валидационной выборке': [lr_valid_f1,\n",
    "                                        dtc_valid_f1,\n",
    "                                        cbc_valid_f1,\n",
    "                                        rfc_valid_f1]}\n",
    "\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "display(f1_data.sort_values(by='F1 на валидационной выборке', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "В ходе работы были обучены 4 модели (LogisticRegression, CatBoostClassifier\t, DecisionTreeClassifier, RandomForestClassifier), каждая сделала предсказания по валидационной выборке, результаты размещены в итоговую таблицу. Как нередко бывает, самое лучшее решение оказалось самым простым - логистическая регрессия справилась с задачей лучше всех."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим предсказания лучшей модели на тестовой выборке и проверим её результат по метрике F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии на тесте: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Предсказания лучшей модели:\n",
    "predictions_test = grid_search_lr.predict(features_test.text)\n",
    "lr_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('F1 логистической регрессии на тесте:', round(lr_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель справилась с поставленной задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговые выводы:\n",
    "На разбор были предоставлены данные из \"Викишопа\" с комментариями пользователей. Задача заключалась в создании модели МО для контроля токсичности данных комментариев.\n",
    "\n",
    "Были загружены и осмотрены предоставленные данные. Пропусков и нулевых значений не обнаружено. Из интересного - доля токсичных комментариев от общего числа составила 10%.\n",
    "\n",
    "Далее: \n",
    "  - Удалён ненужный стобец, дублирующий индексы;\n",
    "  - Произведено преобразование текстовых данных (убраны лишние слова, сделана лемматизация);\n",
    "  - Произведено разбиение на тренировочную, валидационную и тестовую выборки, выровнено количество \"нулевых\" таргетов в тренировочной выборке.\n",
    "  \n",
    "В ходе работы были обучены 4 модели (LogisticRegression, CatBoostClassifier , DecisionTreeClassifier, RandomForestClassifier), каждая сделала предсказания по валидационной выборке, результаты размещены в итоговую таблицу. Как нередко бывает, самое лучшее решение оказалось самым простым - логистическая регрессия справилась с задачей лучше всех.\n",
    "\n",
    "Результаты модели по тестовой выборке также оказались удовлетворительными (F1 = 0,79).\n",
    "\n",
    "Поставленная задача была выполнена в полном объёме, дополнительных исследований не требуется."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1492,
    "start_time": "2024-05-24T11:33:10.751Z"
   },
   {
    "duration": 3391,
    "start_time": "2024-05-24T11:36:06.378Z"
   },
   {
    "duration": 250,
    "start_time": "2024-05-24T11:40:56.568Z"
   },
   {
    "duration": 1054,
    "start_time": "2024-05-24T11:42:09.044Z"
   },
   {
    "duration": 950,
    "start_time": "2024-05-24T11:42:16.087Z"
   },
   {
    "duration": 238,
    "start_time": "2024-05-24T11:42:47.800Z"
   },
   {
    "duration": 52,
    "start_time": "2024-05-24T11:46:11.287Z"
   },
   {
    "duration": 1526,
    "start_time": "2024-05-24T11:46:15.624Z"
   },
   {
    "duration": 1140,
    "start_time": "2024-05-24T11:46:17.152Z"
   },
   {
    "duration": 262,
    "start_time": "2024-05-24T11:46:18.294Z"
   },
   {
    "duration": 1561,
    "start_time": "2024-05-24T11:47:27.573Z"
   },
   {
    "duration": 1107,
    "start_time": "2024-05-24T11:47:29.136Z"
   },
   {
    "duration": 258,
    "start_time": "2024-05-24T11:47:30.245Z"
   },
   {
    "duration": 15,
    "start_time": "2024-05-24T11:47:30.506Z"
   },
   {
    "duration": 180,
    "start_time": "2024-05-24T11:48:28.313Z"
   },
   {
    "duration": 40,
    "start_time": "2024-05-24T11:48:59.494Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-24T11:49:25.604Z"
   },
   {
    "duration": 26,
    "start_time": "2024-05-24T12:11:59.204Z"
   },
   {
    "duration": 4816,
    "start_time": "2024-05-24T12:15:29.269Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-24T12:21:02.051Z"
   },
   {
    "duration": 93838,
    "start_time": "2024-05-24T12:21:26.097Z"
   },
   {
    "duration": 1531,
    "start_time": "2024-05-24T12:24:08.211Z"
   },
   {
    "duration": 1116,
    "start_time": "2024-05-24T12:24:09.745Z"
   },
   {
    "duration": 253,
    "start_time": "2024-05-24T12:24:10.863Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-24T12:24:11.118Z"
   },
   {
    "duration": 41,
    "start_time": "2024-05-24T12:24:11.127Z"
   },
   {
    "duration": 95508,
    "start_time": "2024-05-24T12:24:11.171Z"
   },
   {
    "duration": 163,
    "start_time": "2024-05-24T12:47:52.826Z"
   },
   {
    "duration": 46,
    "start_time": "2024-05-24T12:48:06.315Z"
   },
   {
    "duration": 650,
    "start_time": "2024-05-24T12:50:42.337Z"
   },
   {
    "duration": 662,
    "start_time": "2024-05-24T12:50:55.802Z"
   },
   {
    "duration": 32,
    "start_time": "2024-05-24T12:51:12.994Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-24T12:52:19.768Z"
   },
   {
    "duration": 54,
    "start_time": "2024-05-24T13:01:58.373Z"
   },
   {
    "duration": 60,
    "start_time": "2024-05-24T13:02:21.216Z"
   },
   {
    "duration": 46,
    "start_time": "2024-05-24T13:02:51.445Z"
   },
   {
    "duration": 53,
    "start_time": "2024-05-24T13:03:05.855Z"
   },
   {
    "duration": 56,
    "start_time": "2024-05-24T13:03:24.825Z"
   },
   {
    "duration": 962,
    "start_time": "2024-05-24T13:03:38.223Z"
   },
   {
    "duration": 2579,
    "start_time": "2024-05-24T13:03:48.416Z"
   },
   {
    "duration": 63,
    "start_time": "2024-05-24T13:03:52.505Z"
   },
   {
    "duration": 766,
    "start_time": "2024-05-24T13:30:41.932Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-24T13:31:18.572Z"
   },
   {
    "duration": 1231038,
    "start_time": "2024-05-24T13:31:19.408Z"
   },
   {
    "duration": 132288,
    "start_time": "2024-05-24T13:52:04.741Z"
   },
   {
    "duration": 630215,
    "start_time": "2024-05-24T13:54:17.031Z"
   },
   {
    "duration": 663730,
    "start_time": "2024-05-24T14:04:47.247Z"
   },
   {
    "duration": 1176,
    "start_time": "2024-05-24T18:14:31.431Z"
   },
   {
    "duration": 2161,
    "start_time": "2024-05-24T18:14:32.608Z"
   },
   {
    "duration": 212,
    "start_time": "2024-05-24T18:14:34.771Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-24T18:14:34.985Z"
   },
   {
    "duration": 28,
    "start_time": "2024-05-24T18:14:34.992Z"
   },
   {
    "duration": 71449,
    "start_time": "2024-05-24T18:14:35.021Z"
   },
   {
    "duration": 29,
    "start_time": "2024-05-24T18:15:46.472Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-24T18:15:46.503Z"
   },
   {
    "duration": 28,
    "start_time": "2024-05-24T18:15:46.510Z"
   },
   {
    "duration": 2,
    "start_time": "2024-05-24T18:15:46.540Z"
   },
   {
    "duration": 914288,
    "start_time": "2024-05-24T18:15:46.543Z"
   },
   {
    "duration": 100147,
    "start_time": "2024-05-24T18:31:00.833Z"
   },
   {
    "duration": 510278,
    "start_time": "2024-05-24T18:32:40.981Z"
   },
   {
    "duration": 472486,
    "start_time": "2024-05-24T18:41:11.260Z"
   },
   {
    "duration": 3,
    "start_time": "2024-05-24T20:13:51.452Z"
   },
   {
    "duration": 102,
    "start_time": "2024-05-24T20:14:36.687Z"
   },
   {
    "duration": 14,
    "start_time": "2024-05-24T20:14:46.237Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-24T20:15:15.714Z"
   },
   {
    "duration": 9,
    "start_time": "2024-05-24T20:15:43.874Z"
   },
   {
    "duration": 621,
    "start_time": "2024-05-24T20:21:53.822Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-24T20:22:17.713Z"
   },
   {
    "duration": 1198,
    "start_time": "2024-05-24T20:22:49.981Z"
   },
   {
    "duration": 850,
    "start_time": "2024-05-24T20:22:51.181Z"
   },
   {
    "duration": 220,
    "start_time": "2024-05-24T20:22:52.032Z"
   },
   {
    "duration": 5,
    "start_time": "2024-05-24T20:22:52.254Z"
   },
   {
    "duration": 22,
    "start_time": "2024-05-24T20:22:52.260Z"
   },
   {
    "duration": 71667,
    "start_time": "2024-05-24T20:22:52.283Z"
   },
   {
    "duration": 23,
    "start_time": "2024-05-24T20:24:03.951Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-24T20:24:03.975Z"
   },
   {
    "duration": 46,
    "start_time": "2024-05-24T20:24:03.983Z"
   },
   {
    "duration": 4,
    "start_time": "2024-05-24T20:24:04.031Z"
   },
   {
    "duration": 907109,
    "start_time": "2024-05-24T20:24:04.037Z"
   },
   {
    "duration": 101111,
    "start_time": "2024-05-24T20:39:11.147Z"
   },
   {
    "duration": 513648,
    "start_time": "2024-05-24T20:40:52.259Z"
   },
   {
    "duration": 481332,
    "start_time": "2024-05-24T20:49:25.908Z"
   },
   {
    "duration": 8,
    "start_time": "2024-05-24T20:57:27.242Z"
   },
   {
    "duration": 568,
    "start_time": "2024-05-24T20:57:27.251Z"
   },
   {
    "duration": 1500,
    "start_time": "2024-05-25T11:39:09.036Z"
   },
   {
    "duration": 2379,
    "start_time": "2024-05-25T11:39:11.639Z"
   },
   {
    "duration": 226,
    "start_time": "2024-05-25T11:39:14.020Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-25T11:39:16.340Z"
   },
   {
    "duration": 17,
    "start_time": "2024-05-25T11:39:19.452Z"
   },
   {
    "duration": 349,
    "start_time": "2024-05-25T11:39:21.880Z"
   },
   {
    "duration": 2216471,
    "start_time": "2024-05-25T11:40:05.621Z"
   },
   {
    "duration": 22,
    "start_time": "2024-05-25T12:19:57.824Z"
   },
   {
    "duration": 1380,
    "start_time": "2024-05-25T12:20:50.911Z"
   },
   {
    "duration": 1012,
    "start_time": "2024-05-25T12:20:52.293Z"
   },
   {
    "duration": 259,
    "start_time": "2024-05-25T12:20:53.309Z"
   },
   {
    "duration": 7,
    "start_time": "2024-05-25T12:20:53.569Z"
   },
   {
    "duration": 32,
    "start_time": "2024-05-25T12:20:53.578Z"
   },
   {
    "duration": 2239565,
    "start_time": "2024-05-25T12:20:53.611Z"
   },
   {
    "duration": 21,
    "start_time": "2024-05-25T12:58:13.178Z"
   },
   {
    "duration": 52,
    "start_time": "2024-05-25T12:58:13.201Z"
   },
   {
    "duration": 6,
    "start_time": "2024-05-25T12:58:13.256Z"
   },
   {
    "duration": 59,
    "start_time": "2024-05-25T12:58:13.263Z"
   },
   {
    "duration": 2,
    "start_time": "2024-05-25T12:58:13.324Z"
   },
   {
    "duration": 825782,
    "start_time": "2024-05-25T12:58:13.328Z"
   },
   {
    "duration": 120150,
    "start_time": "2024-05-25T13:11:59.112Z"
   },
   {
    "duration": 579817,
    "start_time": "2024-05-25T13:13:59.264Z"
   },
   {
    "duration": 607030,
    "start_time": "2024-05-25T13:23:39.083Z"
   },
   {
    "duration": 10,
    "start_time": "2024-05-25T13:33:46.115Z"
   },
   {
    "duration": 684,
    "start_time": "2024-05-25T13:33:46.127Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
